{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWpn1RWg1I5E",
        "outputId": "42474477-5fa9-4c38-b727-632a8bde89d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/data_assign_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Hfooe51KV3",
        "outputId": "8cde9811-448d-4c56-df67-7877081b37fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/data_assign_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n"
      ],
      "metadata": {
        "id": "FNYawDYs1Srd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your dataset\n",
        "dataset_dir = 'hand_written_digits'\n",
        "\n"
      ],
      "metadata": {
        "id": "xPSVkxqs1W58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset_path, validation_split=0.2):\n",
        "    classes = ['0_digits', '1_digits', '2_digits']\n",
        "\n",
        "    train_data = []\n",
        "    val_data = []\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        image_list = os.listdir(class_path)\n",
        "        train_images, val_images = train_test_split(image_list, test_size=validation_split, random_state=42)\n",
        "        train_data.extend([(os.path.join(class_path, img), class_name) for img in train_images])\n",
        "        val_data.extend([(os.path.join(class_path, img), class_name) for img in val_images])\n",
        "\n",
        "    return train_data, val_data\n",
        "\n",
        "train_data, val_data = split_dataset(dataset_dir)\n"
      ],
      "metadata": {
        "id": "JEjefQbF223H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width, img_height = 100, 100\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "hPp5l4bK1r2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=False,\n",
        "    vertical_flip=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "ei-kBm2R1xBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained VGG16 model without the top layer\n",
        "base_model = VGG16(input_shape=(img_width, img_height, 3), include_top=False, weights='imagenet')\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add custom classification layers on top\n",
        "x = GlobalAveragePooling2D()(base_model.output)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "output = Dense(3, activation='softmax')(x)  # 3 classes for digits 0, 1, and 2\n"
      ],
      "metadata": {
        "id": "XMTQii6C1zc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the fine-tuned model\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "metadata": {
        "id": "DRUwGMDO12y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare the data\n",
        "train_generator = datagen.flow_from_dataframe(dataframe=pd.DataFrame(train_data, columns=['filename', 'class']),\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(dataframe=pd.DataFrame(val_data, columns=['filename', 'class']),\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkY4nH6f4GYg",
        "outputId": "7ad56910-39c4-4168-c0bc-63e42e77d19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3725 validated image filenames belonging to 3 classes.\n",
            "Found 933 validated image filenames belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the fine-tuned model\n",
        "epochs = 10\n",
        "model.fit(train_generator, validation_data=val_generator, epochs=epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYaKJ_ey16A_",
        "outputId": "44669dd8-3ab5-4ff7-915b-6d752c721fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "117/117 [==============================] - 855s 7s/step - loss: 0.8221 - accuracy: 0.8043 - val_loss: 0.5764 - val_accuracy: 0.9743\n",
            "Epoch 2/10\n",
            "117/117 [==============================] - 351s 3s/step - loss: 0.4338 - accuracy: 0.9764 - val_loss: 0.3193 - val_accuracy: 0.9807\n",
            "Epoch 3/10\n",
            "117/117 [==============================] - 352s 3s/step - loss: 0.2558 - accuracy: 0.9801 - val_loss: 0.2035 - val_accuracy: 0.9893\n",
            "Epoch 4/10\n",
            "117/117 [==============================] - 354s 3s/step - loss: 0.1728 - accuracy: 0.9809 - val_loss: 0.1504 - val_accuracy: 0.9818\n",
            "Epoch 5/10\n",
            "117/117 [==============================] - 353s 3s/step - loss: 0.1235 - accuracy: 0.9850 - val_loss: 0.1093 - val_accuracy: 0.9882\n",
            "Epoch 6/10\n",
            "117/117 [==============================] - 365s 3s/step - loss: 0.0996 - accuracy: 0.9863 - val_loss: 0.0902 - val_accuracy: 0.9839\n",
            "Epoch 7/10\n",
            "117/117 [==============================] - 355s 3s/step - loss: 0.0831 - accuracy: 0.9866 - val_loss: 0.0760 - val_accuracy: 0.9839\n",
            "Epoch 8/10\n",
            "117/117 [==============================] - 366s 3s/step - loss: 0.0727 - accuracy: 0.9879 - val_loss: 0.0697 - val_accuracy: 0.9871\n",
            "Epoch 9/10\n",
            "117/117 [==============================] - 356s 3s/step - loss: 0.0649 - accuracy: 0.9866 - val_loss: 0.0614 - val_accuracy: 0.9861\n",
            "Epoch 10/10\n",
            "117/117 [==============================] - 366s 3s/step - loss: 0.0593 - accuracy: 0.9879 - val_loss: 0.0505 - val_accuracy: 0.9882\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d5778e3ecb0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the fine-tuned model\n",
        "validation_accuracy = model.evaluate(val_generator)[1]\n",
        "print(f'Validation accuracy (Fine-tuned VGG16 Model): {validation_accuracy}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWGrlt3n2FJS",
        "outputId": "0ab212bd-8a58-4ea7-f132-bdf757d08c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30/30 [==============================] - 72s 2s/step - loss: 0.0472 - accuracy: 0.9914\n",
            "Validation accuracy (Fine-tuned VGG16 Model): 0.9914255142211914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zhesZVngIqf8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}